---
title: Ant data Generalized Linear Model - Bayesian
author: Brett Melbourne
date: 5 Nov 2024
output: github_document
---

Third in a series of scripts to analyze the ant data described in Ellison (2004). This script includes Bayesian inference from the GLM, coded explicitly with the function `ulam()` from McElreath's `rethinking` package. Future scripts will consider likelihood and frequentist GLMs with the `lme4` package, and easy Bayesian fitting of GLMs with the `rstanarm` package, and multilevel models to fully account for the design structure.

This script can be rendered to a reproducible report.\
`rmarkdown::render("09_8_ants_bayesian_GLM.Rmd")`, or *Ctrl+Shift+K* in RStudio.

Set up for Bayesian analysis (order is important):

```{r results=FALSE, message=FALSE, warning=FALSE}
library(ggplot2)
library(dplyr)
library(tidyr)
library(rethinking)
# library(rstanarm) #nb overrides default ggplot theme
# options(mc.cores=parallel::detectCores())
# source("source/hpdi.R") #For calculating credible intervals
```

I prefer the black and white theme of ggplot, which we can set for all the plots in this script

```{r}
theme_set(theme_bw())
```


Read in and plot the data

```{r}
ant <- read.csv("data/ants.csv")
ant$habitat <- factor(ant$habitat)
ant |> 
    ggplot(mapping=aes(x=latitude, y=richness, col=habitat)) +
    geom_point()
```

## Model

For the linear predictor, we're going to write the model out explicitly, with the data organized into single-column variables, as in the class slides.

$$
\begin{flalign}
     y_i &\sim \mathrm{Poisson}(\mu_i) && \\
  \eta_i &= \beta_0 \mathrm{intercept}_i + 
            \beta_1 \mathrm{forest}_i + 
            \beta_2 \mathrm{latitude}_i + 
            \beta_3 \mathrm{forest}_i \mathrm{latitude}_i && \\
  \beta_0 &\sim \mathrm{Normal}(0, 10) && \\
  \beta_1 &\sim \mathrm{Normal}(0, 10) && \\
  \beta_2 &\sim \mathrm{Normal}(0, 10) && \\
  \beta_3 &\sim \mathrm{Normal}(0, 10) && \\
  \end{flalign}
$$



## Training

Bayesian fit with `ulam`, spelling out the model. We first need new columns to represent the design matrix.

```{r}
# Set up variables
d <- ant |>
    mutate(intercept=rep(1, n()),
           forest=ifelse(habitat=="forest", 1, 0),
           latitude=scale(latitude),
           forest_X_latitude=forest * latitude) |>
    select(richness, intercept, forest, latitude, forest_X_latitude)
d
```

Now specify the model in full and train with `ulam`. It will take a minute to compile, then it will sample from the posterior.

```{r}
bysfitHxL <- ulam(
    alist(
        richness ~ dpois(mu),
        log(mu) <- beta_0 * intercept +
                   beta_1 * forest +
                   beta_2 * latitude +
                   beta_3 * forest_X_latitude,
        beta_0 ~ dnorm(0,10),
        beta_1 ~ dnorm(0,10),
        beta_2 ~ dnorm(0,10),
        beta_3 ~ dnorm(0,10)
    ),
    data=d,
    chains=4,
    cores=4
)
```


Parameter information

```{r}
precis(bysfitHxL, prob=0.95, digits=4)
```

In the `precis` table, we can look at the posterior sample means (`mean`) for a point estimate of the parameter values. The standard deviation (`sd`) of the posterior samples is one measure of uncertainty. The range between the 2.5 and 97.5 percentiles is a 95% central posterior interval (CPI) for the parameters. The final two columns are MCMC diagnostics. We see especially that the `rhat` values are all 1, indicating convergence, and `ess_bulk`, the effective number of samples, is quite good (800+) for all parameters.

Graphical summary of the parameters:

```{r}
plot(bysfitHxL)
```


Check the traceplot to confirm convergence and check the behavior.

```{r}
traceplot(bysfitHxL)
```


### Working with posterior samples

We'll first work with the samples directly (as we did in McElreath Ch 4). Doing it the slightly harder way first will prepare you for building your own custom analyses by developing a deeper understanding of the data structures as well as experience with visualization. In the next script, we'll do the same analysis with convenient functions in `rstanarm`.

No matter what package or algorithm we use to obtain samples, we want to get those samples because they are the basis for all Bayesian inferences. The object returned by `stan_glm()` includes within it a `stanfit` object and we can use the `extract()` function from `rstan` to get the samples:

```{r}
samples <- extract.samples(bysfitHxL)
class(samples)
str(samples)
names(samples)
```

### Diagnostics

We can plot histograms directly from the samples. To do this with `ggplot`, we first need the samples in a dataframe. We can go one step further, converting the dataframe to tidy format (using `pivot_longer` from `tidyr`) and then using `facet_wrap` to plot histograms for all 4 parameters. First, combine the posterior samples into an appropriate dataframe.

```{r}
samplesdf <- data.frame(samples)
```

Now plot the histograms

```{r}
samplesdf |> 
    pivot_longer(cols=everything(), names_to="parameter", values_to="sample_value") |> 
    ggplot() +
    geom_histogram(mapping=aes(x=sample_value, y=stat(density)), bins=75) +
    facet_wrap(vars(parameter), scales="free")
```

This of course is not merely diagnostic. The posterior distribution is the full inference for a parameter. Diagnostically, we want to ask if the samples are giving us a good picture of the posterior distribution. We see that the distributions of the posterior samples are roughly symmetric (statistical theory for these types of models suggests the posterior would be approximately Normal) and not terribly noisy.

Sometimes you might only want one of the histograms, in which case you can do it quickly without making a data frame by using `hist` from base plot.

```{r eval=FALSE}
hist(samples$beta_0, breaks=75)
```

## Inference

### Parameter credible intervals

We get 95% credible intervals (HPDI) directly from the samples

```{r}
HPDI(samples$beta_0, prob=0.95)
HPDI(samples$beta_1, prob=0.95)
HPDI(samples$beta_2, prob=0.95)
HPDI(samples$beta_3, prob=0.95)
```

These are almost the same as the CPIs due to the symmetric posteriors.

There is a good argument for using the CPI here in lieu of the HPDI. We saw from the histograms that the posteriors are quite symmetric but also that there was still plenty of noise in the tails of the samples. Thus, the CPI is probably a more numerically stable estimate of the credible interval, even though the CPI is not a credible interval itself.

### Mean curves, regression intervals (HPDI), posterior predictive distribution

These quantities don't come directly from the samples for individual parameters but instead are quantities that we derive from combinations of the samples. The following is quite literal. We could make this more elegant but the steps needed are clear this way.

```{r}
# Initialize variables and storage 
latitude <- seq(from=41.92, to=45, length.out=50) #range for latitude
n <- length(latitude)
hpdi_bog <- matrix(NA, nrow=n, ncol=5) #to store hpdi values and mean
colnames(hpdi_bog) <- c("mnmu","mulo95","muhi95","ppdlo95","ppdhi95")
hpdi_forest <- matrix(NA, nrow=n, ncol=5)
colnames(hpdi_forest) <- c("mnmu","mulo95","muhi95","ppdlo95","ppdhi95")

# For each latitude, form the posterior
for ( i in 1:n ) {
    
    # First form samples for the linear predictor \eta
    eta_bog <- samples$beta_0 + 
               samples$beta_2 * latitude[i]
    eta_forest <- samples$beta_0 + 
                  samples$beta_1 + 
                  samples$beta_2 * latitude[i] + 
                  samples$beta_3 * latitude[i]
    
    # Then use inverse link for samples of the posterior \mu
    mu_bog <- exp(eta_bog)
    mu_forest <- exp(eta_forest)
    
    # Sample from Poisson to get the posterior predictive distribution
    ppd_bog <- rpois(n=length(mu_bog), lambda=mu_bog)
    ppd_forest <- rpois(n=length(mu_forest), lambda=mu_forest)
    
    # Mean and intervals of these samples
    hpdi_bog[i,1] <- mean(mu_bog)
    hpdi_bog[i,2:3] <- HPDI(mu_bog, prob=0.95)
    #hpdi_bog[i,4:5] <- hpdi(ppd_bog, prob=0.95)
    hpdi_bog[i,4:5] <- quantile(ppd_bog, prob=c(0.025,0.975)) #CPI
    hpdi_forest[i,1] <- mean(mu_forest)
    hpdi_forest[i,2:3] <- HPDI(mu_forest, prob=0.95)
    #hpdi_forest[i,4:5] <- hpdi(ppd_forest, prob=0.95)
    hpdi_forest[i,4:5] <- quantile(ppd_forest, prob=c(0.025,0.975)) #CPI
    
}
rm(eta_bog, eta_forest, mu_bog, mu_forest) #clean up
```

Notice that we calculated expectations (means) and intervals directly on the scale of the data (the "response" scale), not on the linear predictor scale. If we calculated first on the linear predictor scale and then backtransformed the intervals to the response scale they would be biased due to nonlinear averaging. Also, the posterior predictive distribution (PPD) can, of course, only be on the response scale. I used the CPI (`quantile()`) for the posterior predictive distribution because plots of the HPDI and CPI were substantially similar but the CPI was more numerically stable.

Package in tidy format for plotting

```{r}
predsbog <- data.frame(habitat=rep("bog", n), latitude, hpdi_bog)
predsforest <- data.frame(habitat=rep("forest", n), latitude, hpdi_forest)
preds <- rbind(predsbog, predsforest)
rm(latitude, n, hpdi_bog, hpdi_forest, predsbog, predsforest) #clean up
```

Now we can visualize these inferences. The credible intervals for the means are the shaded regions while the dashed lines show the posterior predictive interval.

```{r}
bfc <- c("#d95f02", "#1b9e77") #bog & forest colors
preds |>
    ggplot() +
    geom_ribbon(mapping=aes(x=latitude, ymin=mulo95, ymax=muhi95, fill=habitat),
                alpha=0.2) +
    geom_point(data=ant, mapping=aes(x=latitude, y=richness, col=habitat)) +
    geom_line(mapping=aes(x=latitude, y=mnmu, col=habitat)) +
    geom_line(mapping=aes(x=latitude, y=ppdlo95, col=habitat), lty=2) +
    geom_line(mapping=aes(x=latitude, y=ppdhi95, col=habitat), lty=2) +
    geom_text(aes(x=42.7, y=3.3, label="Bog"), col=bfc[1]) +
    geom_text(aes(x=43.85, y=9.5, label="Forest"), col=bfc[2]) +
    scale_fill_manual(values=bfc) +
    scale_color_manual(values=bfc) +
    scale_y_continuous(breaks=seq(0, 20, 4), minor_breaks=seq(0, 20, 2)) +
    xlab("Latitude (degrees north)") +
    ylab("Ant species richness") +
    theme(legend.position="none")
```

Notice that the intervals for forest are wider than for bog. This is because the uncertainty scales with the mean of the response. Also notice that the intervals for the posterior predictive distribution have discrete steps. This is because the data generating process is discrete (e.g. we cannot have 1.3 species). Also, there are a few blips in the intervals for the predictive distribution and some wiggles in the mean intervals. This is due to Monte Carlo error. Increase the number of iterations when training the model (e.g. iter=10000) and these will largely go away.

Let's consider now our original three scientific questions. We can answer question 2: How does species richness vary with latitude? The above plot shows this. Species richness declines with latitude and appears to be well described by a gentle exponential decline over the range of the data (because the inverse link function is exponential). The uncertainty in this relationship for both habitats is shown by the credible intervals for the mean. We can also answer question 3: Is this relationship different between habitats? There are two answers, depending on our view. On the one hand, we could conclude from the plot that species richness starts higher and declines faster with latitude in forest than in bog habitat. On the other hand, the exponential decline is about the same and there is little evidence for a difference in the exponent as judged by the value and uncertainty of $\beta_3$ (`habitatforest:latitude`, the difference in the exponent between habitats). The mean and 95% CPI for this parameter is (repeating here from earlier):

```{r}
mean(samples$beta[,3])
posterior_interval(bysfitHxL, pars="habitatforest:latitude", prob=0.95)
```

Finally, we can't properly answer question 1: How different is species richness between habitats? We can see from the plot above that mean species richness is mostly higher in forest than bog, judging by the non-overlap of the credible intervals for the mean. We can also roughly read off the difference (about 5.5 at latitude 42, or 2.5 at latitude 45). But we haven't yet precisely quantified this difference or its uncertainty. 

### Non-standard derived quantities

To answer question 1, we need to make our own relevant quantities: the differences in mean species richness between habitats at different latitudes. These differences are a function of the parameters, so we can **derive** samples of them from samples of the parameters. The first half of this code is substantially the same as above; the main action is at the line that calculates the difference. The object `diff` contains the posterior samples for the difference in mean richness at a given altitude. I found the CPI to be a good and stable estimate of the credible interval.

```{r}
# Initialize variables and storage 
latitude <- seq(from=41.92, to=45, length.out=50) #range for latitude
n <- length(latitude)
forest_bog_diff <- matrix(NA, nrow=n, ncol=3) #to store mean and hpdi values
colnames(forest_bog_diff) <- c("mndiff","difflo95","diffhi95")

# For each latitude, form the posterior
for ( i in 1:n ) {
    
    # First form samples for the linear predictor \eta
    eta_bog <- samples$alpha[,1] + 
               samples$beta[,2] * latitude[i]
    eta_forest <- samples$alpha[,1] + 
                  samples$beta[,1] + 
                  samples$beta[,2] * latitude[i] + 
                  samples$beta[,3] * latitude[i]
    
    # Then use inverse link for samples of the posterior \mu
    mu_bog <- exp(eta_bog)
    mu_forest <- exp(eta_forest)
    
    # Now calculate the habitat difference (derived quantity)
    diff <- mu_forest - mu_bog
    
    # Mean and intervals of these samples
    forest_bog_diff[i,1] <- mean(diff)
    #forest_bog_diff[i,2:3] <- hpdi(diff, prob=0.95)
    forest_bog_diff[i,2:3] <- quantile(diff, prob=c(0.025,0.975)) #CPI

}

# Package in a dataframe
diff_df <- data.frame(cbind(forest_bog_diff, latitude))
rm(latitude,n,forest_bog_diff,eta_bog,eta_forest,mu_bog,mu_forest,diff) #clean up
```

Plot the difference with its uncertainty. I've used `coord_cartesian()` to set the y-axis limits instead of `ylim()` in case the ribbon region goes beyond the axis limit. In `ggplot()` the dataset is truncated to the axis limits by default, which could lead to a missing chunk of the ribbon. The upper limit of the interval is very close to 8 and goes a hair above in some runs of the stochastic sampler.

```{r}
diff_df |> 
    ggplot() +
    geom_ribbon(mapping=aes(x=latitude, ymin=difflo95, ymax=diffhi95),
        alpha=0.2) +
    geom_line(mapping=aes(x=latitude, y=mndiff)) +
    coord_cartesian(ylim=c(0,8)) +
    xlab("Latitude (degrees north)") +
    ylab("Difference in species richness (forest - bog)")
```

Now we have quantitatively answered question 1: How different is species richness between habitats? We can see how the difference declines with latitude, and we can see how the uncertainty changes with latitude showing that mean ant richness in forest is clearly higher than in bog across the entire range of latitudes.

### Using convenience functions

Extracting everything manually from the samples is a fair bit of coding work. The convenience functions in `rstanarm` make this easier for common tasks. As in `glm()`, these functions take a `newdat` argument that simplifies coding. To do what we just did manually above (except for the analysis of the habitat differences), first make a dataframe with the desired values of the explanatory variables.

```{r}
newd <- data.frame(latitude=rep(seq(from=41.92, to=45, length.out=50), 2),
                   habitat=factor(rep(c("bog","forest"), each=50)))
```

Then derive samples for the posterior distribution of the inverse link function, i.e. Dist($\mu$), which we'll call `pmu`.

```{r message=FALSE, }
pmu <- posterior_linpred(bysfitHxL, transform=TRUE, newdata=newd)
```

This is a matrix with samples in rows and the variable combinations in columns. The estimated means are then

```{r}
mnmu <- colMeans(pmu)
```

and the 95% credible intervals for the mean are

```{r}
n <- nrow(newd)
regression_intervals <- data.frame(mulo95=rep(NA,n), muhi95=rep(NA,n))
for ( i in 1:n ) {
    regression_intervals[i,] <- hpdi(pmu[,i], prob=0.95)
}
```

For predictions, first derive samples for the posterior predictive distribution, which we'll call ppd

```{r}
ppd <- posterior_predict(bysfitHxL, newdata=newd)
str(ppd)
```

and the 95% prediction intervals (here CPI for stability) are then

```{r}
n <- nrow(newd)
prediction_intervals <- data.frame(ppdlo95=rep(NA,n), ppdhi95=rep(NA,n))
for ( i in 1:n ) {
    prediction_intervals[i,] <- quantile(ppd[,i], prob=c(0.025,0.975))
}
```

Plot (code is the same as the previous plot of the regression means)

```{r}
preds <- cbind(newd, mnmu, regression_intervals, prediction_intervals)
bfc <- c("#d95f02", "#1b9e77") #bog & forest colors
preds |>
    ggplot() +
    geom_ribbon(mapping=aes(x=latitude, ymin=mulo95, ymax=muhi95, fill=habitat),
                alpha=0.2) +
    geom_point(data=ant, mapping=aes(x=latitude, y=richness, col=habitat)) +
    geom_line(mapping=aes(x=latitude, y=mnmu, col=habitat)) +
    geom_line(mapping=aes(x=latitude, y=ppdlo95, col=habitat), lty=2) +
    geom_line(mapping=aes(x=latitude, y=ppdhi95, col=habitat), lty=2) +
    geom_text(aes(x=42.7, y=3.3, label="Bog"), col=bfc[1]) +
    geom_text(aes(x=43.85, y=9.5, label="Forest"), col=bfc[2]) +
    scale_fill_manual(values=bfc) +
    scale_color_manual(values=bfc) +
    scale_y_continuous(breaks=seq(0, 20, 4), minor_breaks=seq(0, 20, 2)) +
    xlab("Latitude (degrees north)") +
    ylab("Ant species richness") +
    theme(legend.position="none")
```

## Summary

Comparing inference algorithms for frequentist and Bayesian approaches to model means and predictions so far:

| Tool     | Mean                      | Uncertainty of mean       | Uncertainty of prediction |
|:-----------------|:-----------------|:-----------------|:-----------------|
| lm       | predict()                 | predict(int="confidence") | predict(int="prediction") |
| glm      | predict(type= "response") | predict(se.fit=TRUE)      | via bootstrap             |
|          |                           | or via bootstrap          |                           |
| stan_glm | mean(pmu)                 | hpdi(pmu)                 | hpdi(ppd)                 |

where:

-   `pmu <- posterior_linpred(transform = TRUE)`
-   `ppd <- posterior_predict()`
